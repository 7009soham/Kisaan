{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "186d0bd4",
   "metadata": {},
   "source": [
    "# Kisaan Colab Training (GPU)\n",
    "Use this notebook on Google Colab to fine-tune the Topic and Sub-topic heads with PEFT/LoRA, then run inference on the combined CSV. Run cells top-to-bottom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c42137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Configure project paths\n",
    "from pathlib import Path\n",
    "import os\n",
    "import json\n",
    "PROJECT_DIR = Path(\"/content/Kisaan\")  # path after cloning the GitHub repo\n",
    "DATASET_PATH = PROJECT_DIR / \"Datasets\" / \"KCC_MarMay2025_combined.csv\"\n",
    "MODELS_DIR = PROJECT_DIR / \"models\"\n",
    "PROCESSED_DIR = PROJECT_DIR / \"Datasets\" / \"processed\"\n",
    "print(\"Project directory:\", PROJECT_DIR)\n",
    "print(\"Dataset path:\", DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107684b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. (Optional) Mount Google Drive for long-term storage\n",
    "IN_COLAB = False\n",
    "try:\n",
    "    import google.colab  # type: ignore\n",
    "    IN_COLAB = True\n",
    "except Exception:\n",
    "    pass\n",
    "print({\"IN_COLAB\": IN_COLAB})\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive  # type: ignore\n",
    "    drive.mount(\"/content/drive\", force_remount=False)\n",
    "    DRIVE_PROJECT_DIR = Path(\"/content/drive/MyDrive/Kisaan\")\n",
    "    print(\"Drive project dir:\", DRIVE_PROJECT_DIR)\n",
    "else:\n",
    "    print(\"Not running inside Colab; skipping Drive mount.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0cc3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Clone the GitHub repository if not present\n",
    "import subprocess\n",
    "import sys\n",
    "if not PROJECT_DIR.exists():\n",
    "    subprocess.run([\"git\", \"clone\", \"https://github.com/7009soham/Kisaan.git\", str(PROJECT_DIR)], check=True)\n",
    "else:\n",
    "    print(\"Repository already present at\", PROJECT_DIR)\n",
    "%cd {PROJECT_DIR}\n",
    "!git status -sb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87b19b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Install dependencies (ensures recent Transformers/PEFT)\n",
    "!pip install --quiet --upgrade \\\n",
    "    transformers==4.46.1 \\\n",
    "    datasets==3.0.1 \\\n",
    "    accelerate==1.0.1 \\\n",
    "    peft==0.13.2 \\\n",
    "    evaluate==0.4.2 \\\n",
    "    sentencepiece==0.1.99 \\\n",
    "    scikit-learn==1.5.2 \\\n",
    "    pandas==2.2.3 \\\n",
    "    numpy==1.26.4 \\\n",
    "    tqdm==4.66.5 \\\n",
    "    pyarrow==16.1.0 \\\n",
    "    matplotlib==3.9.2 \\\n",
    "    seaborn==0.13.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68703cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Validate dataset paths\n",
    "assert DATASET_PATH.exists(), f\"Dataset not found: {DATASET_PATH}\"\n",
    "print(\"Dataset rows:\", sum(1 for _ in open(DATASET_PATH, encoding=\"utf-8-sig\")) - 1)\n",
    "print(\"Ready to preprocess labels.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
