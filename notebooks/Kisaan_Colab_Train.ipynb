{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "186d0bd4",
   "metadata": {},
   "source": [
    "# Kisaan Colab Training (GPU)\n",
    "Use this notebook on Google Colab to fine-tune the Topic and Sub-topic heads with PEFT/LoRA, then run inference on the combined CSV. Run cells top-to-bottom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c42137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Configure project paths\n",
    "from pathlib import Path\n",
    "import os\n",
    "import json\n",
    "PROJECT_DIR = Path(\"/content/Kisaan\")  # path after cloning the GitHub repo\n",
    "DATASET_PATH = PROJECT_DIR / \"Datasets\" / \"KCC_MarMay2025_combined.csv\"\n",
    "MODELS_DIR = PROJECT_DIR / \"models\"\n",
    "PROCESSED_DIR = PROJECT_DIR / \"Datasets\" / \"processed\"\n",
    "print(\"Project directory:\", PROJECT_DIR)\n",
    "print(\"Dataset path:\", DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107684b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. (Optional) Mount Google Drive for long-term storage\n",
    "IN_COLAB = False\n",
    "try:\n",
    "    import google.colab  # type: ignore\n",
    "    IN_COLAB = True\n",
    "except Exception:\n",
    "    pass\n",
    "print({\"IN_COLAB\": IN_COLAB})\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive  # type: ignore\n",
    "    drive.mount(\"/content/drive\", force_remount=False)\n",
    "    DRIVE_PROJECT_DIR = Path(\"/content/drive/MyDrive/Kisaan\")\n",
    "    print(\"Drive project dir:\", DRIVE_PROJECT_DIR)\n",
    "else:\n",
    "    print(\"Not running inside Colab; skipping Drive mount.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0cc3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Clone the GitHub repository if not present\n",
    "import subprocess\n",
    "import sys\n",
    "if not PROJECT_DIR.exists():\n",
    "    subprocess.run([\"git\", \"clone\", \"https://github.com/7009soham/Kisaan.git\", str(PROJECT_DIR)], check=True)\n",
    "else:\n",
    "    print(\"Repository already present at\", PROJECT_DIR)\n",
    "%cd {PROJECT_DIR}\n",
    "!git status -sb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87b19b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Install dependencies (Python 3.12 compatible)\n",
    "!pip install --quiet --no-cache-dir --upgrade \\\\\n",
    "    torch \\\\\n",
    "    transformers==4.46.1 \\\\\n",
    "    datasets==3.0.1 \\\\\n",
    "    accelerate==1.0.1 \\\\\n",
    "    peft==0.13.2 \\\\\n",
    "    sentencepiece==0.1.99 \\\\\n",
    "    scikit-learn==1.5.2 \\\\\n",
    "    pandas==2.2.3 \\\\\n",
    "    numpy==2.1.1 \\\\\n",
    "    tqdm==4.66.5 \\\\\n",
    "    pyarrow==16.1.0 \\\\\n",
    "    matplotlib==3.9.2 \\\\\n",
    "    seaborn==0.13.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04573ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4b. Verify library versions (ensure imports use new wheels)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "print('numpy', np.__version__)\n",
    "print('pandas', pd.__version__)\n",
    "print('sklearn', sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68703cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Validate dataset paths\n",
    "assert DATASET_PATH.exists(), f\"Dataset not found: {DATASET_PATH}\"\n",
    "print(\"Dataset rows:\", sum(1 for _ in open(DATASET_PATH, encoding=\"utf-8-sig\")) - 1)\n",
    "print(\"Ready to preprocess labels.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7b6c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Preprocess dataset for stable stratified splits\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "df_full = pd.read_csv(DATASET_PATH, encoding=\"utf-8-sig\")\n",
    "def ensure_column(df, label_col):\n",
    "    if label_col not in df.columns:\n",
    "        if label_col == \"topic\" and \"QueryType\" in df.columns:\n",
    "            df[label_col] = df[\"QueryType\"].fillna(\"Other\")\n",
    "        else:\n",
    "            df[label_col] = \"Other\"\n",
    "    df[label_col] = df[label_col].fillna(\"Other\").astype(str)\n",
    "    return df\n",
    "def sanitize_label_column(series):\n",
    "    def split_labels(val):\n",
    "        parts = [p.strip() for p in str(val).split(\";\") if p.strip()]\n",
    "        return parts if parts else [\"Other\"]\n",
    "    first_labels = series.apply(lambda s: split_labels(s)[0])\n",
    "    counts = first_labels.value_counts()\n",
    "    rare = set(counts[counts < 2].index)\n",
    "    def replace_if_rare(val):\n",
    "        parts = split_labels(val)\n",
    "        return \"Other\" if parts[0] in rare else \";\".join(parts)\n",
    "    return series.apply(replace_if_rare)\n",
    "processed_paths = {}\n",
    "for col in [\"topic\", \"sub_topic\"]:\n",
    "    df = ensure_column(df_full.copy(), col)\n",
    "    df[col] = sanitize_label_column(df[col])\n",
    "    out_path = PROCESSED_DIR / f\"KCC_MarMay2025_{col}_train.csv\"\n",
    "    df.to_csv(out_path, index=False, encoding=\"utf-8-sig\")\n",
    "    processed_paths[col] = out_path\n",
    "    print(f\"Prepared {col} dataset -> {out_path}\")\n",
    "processed_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba93a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Train Topic head with PEFT/LoRA\n",
    "topic_data = processed_paths[\"topic\"]\n",
    "topic_out = MODELS_DIR / \"topic\"\n",
    "topic_out.mkdir(parents=True, exist_ok=True)\n",
    "!python src/train_topic_subtopic_peft.py \\\n",
    "    --data_csv \"{topic_data}\" \\\n",
    "    --out_dir \"{topic_out}\" \\\n",
    "    --label_col topic \\\n",
    "    --text_col QueryText \\\n",
    "    --base_model xlm-roberta-base \\\n",
    "    --epochs 4 \\\n",
    "    --batch_size 16 \\\n",
    "    --max_length 160 \\\n",
    "    --lr 2e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73b9874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Train Sub-topic head\n",
    "sub_data = processed_paths[\"sub_topic\"]\n",
    "sub_out = MODELS_DIR / \"subtopic\"\n",
    "sub_out.mkdir(parents=True, exist_ok=True)\n",
    "!python src/train_topic_subtopic_peft.py \\\n",
    "    --data_csv \"{sub_data}\" \\\n",
    "    --out_dir \"{sub_out}\" \\\n",
    "    --label_col sub_topic \\\n",
    "    --text_col QueryText \\\n",
    "    --base_model xlm-roberta-base \\\n",
    "    --epochs 4 \\\n",
    "    --batch_size 16 \\\n",
    "    --max_length 160 \\\n",
    "    --lr 2e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee4482f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Run inference on the full combined CSV\n",
    "scored_csv = PROJECT_DIR / \"Datasets\" / \"KCC_MarMay2025_scored.csv\"\n",
    "!python src/predict_local.py \\\n",
    "    --data_csv \"{DATASET_PATH}\" \\\n",
    "    --model_topic \"{topic_out}\" \\\n",
    "    --model_subtopic \"{sub_out}\" \\\n",
    "    --text_col QueryText \\\n",
    "    --out_csv \"{scored_csv}\" \\\n",
    "    --device auto \\\n",
    "    --batch_size 64\n",
    "assert scored_csv.exists(), f\"Scored file missing: {scored_csv}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53df10b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Preview predictions\n",
    "import pandas as pd\n",
    "df_scored = pd.read_csv(scored_csv, encoding=\"utf-8-sig\")\n",
    "cols = [c for c in df_scored.columns if c.startswith(\"prob_topic::\")]\n",
    "print(df_scored[[\"QueryText\", \"pred_topic\", \"pred_sub_topic\"] + cols[:5]].head())\n",
    "print(\"Saved scored CSV ->\", scored_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfa8c8c",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "- Download `models/topic`, `models/subtopic`, and `Datasets/KCC_MarMay2025_scored.csv` for local CPU inference.\n",
    "- Update thresholds or taxonomy and re-run as needed.\n",
    "- (Optional) Sync artifacts back to `/content/drive/MyDrive/Kisaan` for persistence."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
